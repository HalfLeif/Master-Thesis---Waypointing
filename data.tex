\section{Datasets}

Here we describe some existing datasets for historical handwriting recognition and information extraction. We also consider their usefulness in regard to the thesis.

% TODO add some pictures here?
% Describe data sets MNIST, IRIS, SWE as well as other unused ones.

% TODO add citations for each mentioned data set?

\subsection{Datasets for historical handwriting recognition}
Several collections of historical documents have been line segmented and transcribed for public use \cite{esposalles}: George Washington, Parzival, Saint Gall, RODRIGO and GERMANA. However, they consist of prose written by one or two scribes and not civil population records which are typically written by many different scribes.

\subsection{Esposalles}
In contrast, the Esposalles dataset consists of book indices and historical marriage licenses from the Cathedral of Barcelona \cite{esposalles}. Experts have manually segmented and transcribed each word exactly as they occur in the image.

Although the Cathedral of Barcelona holds 291 books containing approximately 600 000 marriage licenses between 1451 and 1905, only a tiny fraction of this collection has been transcribed for the Esposalles dataset. The dataset consists of 173 pages from a single book written by a single scribe, containing 1747 marriage licenses between 1617 and 1619. Additionally, the dataset contains 29 pages of book indices.

The Esposalles dataset was used as ground truth for named entity recognition in the Robust reading competition at the International Conference on Document Analysis and Recognition (ICDAR) 2017 \cite{EsposallesCompetition}. For the competition, the words have been annotated with semantic categories such as surname of husband and surname of wife.

We think that the exact transcriptions, bounding boxes and annotations make the dataset useful for segmentation-based methods in tasks like word segmentation, handwriting recognition and named entity recognition.
Specifically for this thesis, we intend to classify years in a much larger range than 1617 to 1619 so the Esposalles dataset is simply too small. Furthermore, we are interested in exploring segmentation-free methods so we would not take advantage of the bounding boxes present in this dataset.

% TODO perhaps argue about slow and expensive process?
% We argue that creating a dataset of exact transcriptions and annotations by using paleographical experts is too slow and expensive to make a sufficiently large

%Furthermore, we believe that in order to make a system for fully automated indexing, the dataset needs to cover many more examples. Since using paleographical experts to transcribe and annotate each word is a slow and expensive process we do not expect the dataset to grow quickly.
% Thus, we assume that in order to create a sufficiently large dataset for training
%Thus we argue that for a dataset to grow sufficiently large it should
%1. not require the transcriber to be an expert and 2.
%only contain the most vital coarse information instead of every single word.


\subsection{IRIS}

While the Esposalles dataset focus on individual words transcribed by experts, the IRIS dataset contain record information extracted by volunteers in FamilySearch's indexing program \cite{Iris}.
Thus the extracted information does not contain exact transcriptions of the text but rather the most important semantic contents.
For example, abbreviations may have been expanded, dittos replaced by their intended values and information that was deemed genealogically irrelevant has been ignored.
Furthermore, while in Esposalles each transcribed word has a manually created bounding box, in IRIS there is no indication about what part of the image the information was extracted from.

The IRIS dataset consist of four collections of population records, totaling nearly $50000$ images:

\paragraph{1, 2}
The first two collections in the IRIS dataset are the 1930 population census in the US and Mexico. The images consist of big tables with names and occupations in the cells.
For the purpose of this thesis where we extract the written year for each page, the 1930 censuses are not directly useful since they only contains records from a single year. Furthermore, it is not clear that if a system can learn from this collection that it would by useful for any other collection.
However because the 1930 censuses are written on printed tables, word segmentation should be considerably simpler than for the free-form writing as in other collections.

\paragraph{3}
The third collection contains marriage licenses between 1837-1944 in Arkansas. The marriage licenses are printed templates with handwritten text in the blanks.
It is likely that the system would learn to recognize the printed template and hence it would not be able to generalize to other collections that use different templates or free-form writing. If many collections were using the same template it would be useful to learn but then one might as well hard-code the positions of the blanks in the template. Thus, it is not very useful as training-data for models in this thesis.

\paragraph{4}
The last collection contains more than 10000 pages with records of baptisms, burials and marriages from French parishes between 1533-1906. Some of the pages contain printed templates but the majority seems to be free-form handwriting.
From manually inspecting these images, we conclude that many of them do not contain a written year anywhere on the page. These are problems that a future automated extraction system would need to handle, for this thesis however we settle for another dataset that seems somewhat easier.


\subsection{Swedish population records}

\input{figures/collections}

In cooperation with FamilySearch for making this thesis, we have been granted access to manually indexed images from six Swedish collections, see Table \ref{tab:collections}. They contain records of births, deaths and marriages between 1627 and 1890. Like with the IRIS dataset, the images are not completely transcribed but the relevant genealogical information is extracted.
