
%% CNNs

% Fornes:
%
% General field: DIAR = Document image analysis and recognition
% HWR needs optical model + linguistic model.
% For extraction also need NER by grammars/NLP etc.
%
% Use CNN directly on word images to categorize into 6 categories.
% Spatial pyramid pooling so input images can have different sizes without distorting the input.
%
% Better to use 3x3 filters and ReLU to avoid vanishing gradient.
% Need Dropout in fully connected layer to avoid overfitting.
@inproceedings{FornesCnnCategorization,
  title={Handwritten Word Image Categorization with Convolutional Neural Networks and Spatial Pyramid Pooling},
  author={Toledo, J Ignacio and Sudholt, Sebastian and Forn{\'e}s, Alicia and Cucurull, Jordi and Fink, Gernot A and Llad{\'o}s, Josep},
  booktitle={Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)},
  pages={543--552},
  year={2016},
  organization={Springer}
}

@article{AlphaGo,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{AlphaGoTuringTest,
  title={Where does AlphaGo go: from Church-Turing thesis to AlphaGo thesis and beyond},
  author={Wang, Fei-Yue and Zhang, Jun Jason and Zheng, Xinhu and Wang, Xiao and Yuan, Yong and Dai, Xiaoxiao and Zhang, Jie and Yang, Liuqing},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={3},
  number={2},
  pages={113--120},
  year={2016},
  publisher={IEEE}
}

% Spark of interest for CNNs.
% ReLU activation good against vanishing gradient problem.
@inproceedings{AlexNet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

% CNNs much attention since AlexNet 2012.
% Becoming deeper and deeper in 2014.
%
% Better to use several 3x3 than single 5x5 or larger filters.
% Suggest refactorizations to avoid representation bottlenecks while still reducing computation speed due to fewer parameters.
@inproceedings{InceptionV3,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2818--2826},
  year={2016}
}

% Optimize input image to maximize filter activation.
% Saliency maps
@article{VisualizeCnn,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

% Machine translation from subproblems to RNN encoder/decoder approach
% Reuse same architecture but CNN for encoder.
% Source code uses Inception v3 for CNN network pretrained on image classification.
@inproceedings{ShowAndTell,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3156--3164},
  year={2015}
}

%% Attention models

@article{DeepMindAttention,
   author = {{Mnih}, V. and {Heess}, N. and {Graves}, A. and {Kavukcuoglu}, K.
	},
    title = "{Recurrent Models of Visual Attention}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1406.6247},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
     year = 2014,
    month = jun,
%   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1406.6247M},
%   adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

% Based on ShowAndTell above but with attention model.
@article{AttendAndTell,
   author = {{Xu}, K. and {Ba}, J. and {Kiros}, R. and {Cho}, K. and {Courville}, A. and
	{Salakhutdinov}, R. and {Zemel}, R. and {Bengio}, Y.},
    title = "{Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1502.03044},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition},
     year = 2015,
    month = feb,
%   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150203044X},
%   adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

% Neural machine traslations often use encoder/decoder. However they often have a fixed length intermediate representation which can't accurately represent long sentences. Instead, encode input as sequence of vectors and use attention model to select which one.
@article{machine_translation_attention,
   author = {{Bahdanau}, D. and {Cho}, K. and {Bengio}, Y.},
    title = "{Neural Machine Translation by Jointly Learning to Align and Translate}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1409.0473},
 primaryClass = "cs.CL",
 keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
     year = 2014,
    month = sep,
%   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1409.0473B},
%   adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

% Visual-semantic alignment
@inproceedings{VisualSemanticAlignment,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3128--3137},
  year={2015}
}

% Original R-CNN article
%
% Takes image classification system (AlexNet) and applies it to object detection.
% Sliding-window detector technically difficult because higher layers have a large receptive field.
% Exist many region selection methods, uses Selective search. Warps output image to fix size.
@inproceedings{RCNN,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}

% Region proposal only course suggestion, need to be refined further.
@inproceedings{FastRCNN,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1440--1448},
  year={2015}
}

@inproceedings{FasterRCNN,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in neural information processing systems},
  pages={91--99},
  year={2015}
}
