
\chapter{Alternative methods}
% "conventional methods" ?
\textit{ We have previously described how neural networks, especially convolutional neural networks, can be applied to image classification problem, and by extension, transcription.
For completeness, we here give a brief overview of some alternative methods for handwriting recognition and transcription that are not used in this thesis.
In the next chapter we compare our work with previously mentioned related work and consider segmentation for future work, which is introduced in this chapter.
}

% In this section we describe traditional methods for related tasks: text recognition and word spotting. In this thesis however, we have chosen to use a different approach based on neural networks, which are discussed in depth in section \ref{sec:networks}.

%% Rewrite this part, add more recent work, especially in deep learning and CNNs: spatial transformations, visual-semantic alignment etc.

\section{Handwritten text recognition} \label{sec:alt_htr}

Handwritten text recognition (HTR) systems have
% been employed successfully in industry for
seen commercial success in
% been employed with commercial success for
recognizing postal addresses on letters \cite{lecun_1989, zipcode_system} and reading bank cheques. This has been possible because (1) the text is in a very small domain and (2) these applications have high market value \cite{40_years_HWR}. However, transcribing a natural language in general is still an unsolved problem.

% \subsubsection{}
HTR solutions can typically be described by four steps \cite{offline_HWR_CNN}:
\begin{enumerate}
    \item Pre-processing - each pixel in the image is mapped to either 0 or 1, skew is corrected and noise is removed.
    \item Segmentation - the image is cut into small segments, so that each segment contains a handwritten word.
    \item Feature extraction - each image segment is encoded into some vector of features.
    \item Classification - the feature vector is interpreted as a word from a known vocabulary.
\end{enumerate}

A comprehensible survey of common techniques for the different steps can be found here \cite{HWR_survey}.
Previous work on HTR include \textbf{Hidden markov models} (HMMs) in combination with neural networks \cite{Offline_HWR_HMM_ANN}.
More recent approaches include multi-stream HMMs \cite{HWR_multi_stream_HMM_arabic}, HMMs with \textbf{recurrent neural networks} (RNNs) \cite{Offline_HWR_RNN} and deep \textbf{convolutional neural networks} (CNNs) \cite{offline_HWR_CNN}.

\subsection{Pre-processing}

Pre-processing is commonly used to improve the quality of the input \cite{HWR_survey}. However, successful attempts have been made without pre-processing \cite{FornesCnnCategorization}. We only describe binarization and skew detection but \textbf{noise reduction} and \textbf{line detection} are also common pre-processing tasks.

\subsubsection{Binarization}

Binarization maps each pixel to 0 or 1 depending on whether the gray-scale value of the pixel is above or below some threshold.
Binarizing the image is necessary for some techniques that count black pixels
% such as projection-based skew detection,
or use connected components (CCs). A connected component is simply a group of adjacent black pixels surrounded by white pixels in the binarized image.

The simplest is to use a global threshold, often calculated by Otsu's method. Otsu's method looks at the intensity histogram of the image. Assuming that there are two peaks in the histogram, one for background and one for foreground, it attempts to find a balanced threshold between the peaks. If the lighting was uneven at the time of photography, global thresholding does not work very well.

Another approach is to use local or adaptive thresholds, which calculates different thresholds for each pixel depending on the surrounding area. Local thresholds are more successful than global thresholding on low quality images, especially in the presence of noise. There are extensions to Otsu's method to produce local thresholds.

Neural networks have also been used to combine global and local thresholds for binarization.

\subsubsection{Skew detection}

Skew, or rotation, in images of text can be detected by computing the horizontal projection for different angles. The horizontal projection counts the number of black pixels per row, which requires the above described binarization. The amplitude of the projection is maximized when the image rotation is aligned with the text.

% \subsubsection{Noise reduction}
%
% Median filtering...
%
% \subsubsection{Line detection}

\subsection{Segmentation}

Segmentation produces bounding boxes around detected words in the input image to be transcribed. The resulting word images can then be used as input for feature extraction. In order to produce word segments, most methods first segment the text lines.

There are many methods that have been proposed for word image segmentation \cite{HWR_survey, Waterflow2011, Waterflow2015}.

\subsubsection{Projections}

The simplest group of methods is based on projections of the image. For example pixel counting, which cuts the image into line segments on the rows where the number of black pixels is below a threshold. However, this approach assumes the text to be written on straight lines, which is often true for printed text but it does not hold for free-form handwriting. Another problem is if there are multiple lines in the image which are not aligned.

\subsubsection{Smearing}

Smearing is another group of methods that grows a boundary from each black pixel and groups the black pixels whose boundaries overlap. The water flow algorithm seems promising from this group of methods since it can handle curved text quite well \cite{Waterflow2011, Waterflow2015}.

\subsubsection{Graphs}

Another successful approach is to represent the connected components in the binarized image as vertices in a weighted graph \cite{GraphSegmentation}.
% For each pair of connected components we compute a connectivity metric $c$, which is based on the Euclidian distance, and form an edge between the corresponding vertices with weight $c$.
For each pair of vertices we create an edge, whose weight takes the value of a connectivity metric based on the Euclidian distance between the two connected components.
% We compute a connectivity metric based on the Euclidian distance between all connected components.
% Each edge between two vertices takes a weight
% For weights, we use a connectivity metric that is based on the closest Euclidian distance between the two connected components.
% The weight between two vertices is based
% Every edge between two vertices is associated with a connectivity metric,
% The edges of the graph use a connectivity metric for weight,
% which is based on the closest Euclidian distance between the two connected components.
% The minimum spanning tree for the graph can be computed and cut into subgraphs which become segments. The cutting can be done by using a pre-determined threshold for the connectivity metric.
The segments are created by cutting the minimum spanning tree of the graph at every edge whose weight is lower than some pre-determined threshold.

\subsubsection{Recursive}

Yet another approach is recursive methods, which use a reference library of word images.
Recursive methods attempt to find a sequence of segments such that each segment matches some reference word image within a pre-defined error threshold.
% attempt to find a sequence of segments so that each segment matches some word image within a certain error threshold.
One obvious problem is that the method requires a library that contains similar words as in the image. On the one hand, genealogical records use the same words many times like \textquote{born} and \textquote{father}; on the other hand, handwriting has so many variations that it may be difficult to create a sufficiently large library.
% Since handwriting has so many variations, it may be difficult to create a sufficiently large library.



% Stochastic methods utilize HMMs to ...



% \section{Word spotting}
%
% Mention alternative approach to aid waypointing by using segmentation free word spotting to compile word image clouds. However, does not help towards automated indexing. Cite Uppsala.
%
% \section{Named entity recognition}
%
% \textbf{Named entity recognition} (NER) ...?
